{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/david/miniconda3/envs/genai/lib/python3.11/site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in /Users/david/miniconda3/envs/genai/lib/python3.11/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_community\n",
    "# !pip install PyPDF2\n",
    "# !pip install docx\n",
    "# !pip install exceptions\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyCNqhvDvU0Ex8tZPUG_1zbkraLjnjQxlQc'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing documents...\n",
      "Documents processed successfully!\n",
      "\n",
      "Ask questions about food reviews (type 'quit' to exit):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import Document\n",
    "import PyPDF2\n",
    "try:\n",
    "    from docx import Document as DocxDocument\n",
    "    DOCX_SUPPORT = True\n",
    "except ImportError:\n",
    "    DOCX_SUPPORT = False\n",
    "from config import Config\n",
    "\n",
    "# Configure Gemini API\n",
    "GOOGLE_API_KEY = Config.GEMINI_API_KEY\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "class FoodReviewRAG:\n",
    "    def __init__(self, documents_dir: str):\n",
    "        self.documents_dir = documents_dir\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\",\n",
    "            google_api_key=GOOGLE_API_KEY\n",
    "        )\n",
    "        self.llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-pro\",\n",
    "            temperature=0.7,\n",
    "            google_api_key=GOOGLE_API_KEY\n",
    "        )\n",
    "        self.vector_store = None\n",
    "        self.qa_chain = None\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "    def load_documents(self) -> List[Document]:\n",
    "        \"\"\"Load documents from the specified directory.\"\"\"\n",
    "        documents = []\n",
    "        for filename in os.listdir(self.documents_dir):\n",
    "            file_path = os.path.join(self.documents_dir, filename)\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    text = file.read()\n",
    "                    documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
    "            elif filename.endswith('.pdf'):\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    for i, page in enumerate(pdf_reader.pages):\n",
    "                        text = page.extract_text()\n",
    "                        documents.append(Document(page_content=text, metadata={\"source\": f\"{filename} - page {i+1}\"}))\n",
    "            elif filename.endswith('.docx') and DOCX_SUPPORT:\n",
    "                doc = DocxDocument(file_path)\n",
    "                text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "                documents.append(Document(page_content=text, metadata={\"source\": filename}))\n",
    "            elif filename.endswith('.docx') and not DOCX_SUPPORT:\n",
    "                print(f\"Warning: .docx support is not available. Skipping {filename}\")\n",
    "        return documents\n",
    "\n",
    "    def process_documents(self):\n",
    "        \"\"\"Process documents and create vector store.\"\"\"\n",
    "        # Load documents\n",
    "        documents = self.load_documents()\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vector_store = FAISS.from_documents(chunks, self.embeddings)\n",
    "        \n",
    "        # Create QA chain\n",
    "        self.qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=self.llm,\n",
    "            retriever=self.vector_store.as_retriever(),\n",
    "            memory=self.memory,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "    def query(self, question: str) -> Dict:\n",
    "        \"\"\"Query the RAG system with a question.\"\"\"\n",
    "        if not self.qa_chain:\n",
    "            raise ValueError(\"Please process documents first by calling process_documents()\")\n",
    "        \n",
    "        result = self.qa_chain({\"question\": question})\n",
    "        return {\n",
    "            \"answer\": result[\"answer\"],\n",
    "            \"source_documents\": result[\"source_documents\"]\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Initialize RAG system\n",
    "    rag = FoodReviewRAG(\"foodreview\")\n",
    "    \n",
    "    # Process documents\n",
    "    print(\"Processing documents...\")\n",
    "    rag.process_documents()\n",
    "    print(\"Documents processed successfully!\")\n",
    "    \n",
    "    # Interactive query loop\n",
    "    print(\"\\nAsk questions about food reviews (type 'quit' to exit):\")\n",
    "    while True:\n",
    "        question = input(\"\\nYour question: \")\n",
    "        if question.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            result = rag.query(question)\n",
    "            print(\"\\nAnswer:\", result[\"answer\"])\n",
    "            print(\"\\nSources:\")\n",
    "            for doc in result[\"source_documents\"]:\n",
    "                print(\"-\", doc.page_content[:200], \"...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genai)",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
