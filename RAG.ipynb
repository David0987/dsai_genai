{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement exceptions (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for exceptions\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_community\n",
    "# !pip install PyPDF2\n",
    "# !pip install docx\n",
    "# !pip install exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversationBufferMemory\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocx\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Configure Gemini API\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai/lib/python3.11/site-packages/docx.py:30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     28\u001b[39m     TAGS = {}\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'exceptions'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from config import Config\n",
    "\n",
    "# Configure Gemini API\n",
    "GOOGLE_API_KEY = Config.GEMINI_API_KEY\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "class FoodReviewRAG:\n",
    "    def __init__(self, documents_dir: str):\n",
    "        self.documents_dir = documents_dir\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
    "        self.vector_store = None\n",
    "        self.qa_chain = None\n",
    "        self.memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "    def load_documents(self) -> List[str]:\n",
    "        \"\"\"Load documents from the specified directory.\"\"\"\n",
    "        documents = []\n",
    "        for filename in os.listdir(self.documents_dir):\n",
    "            file_path = os.path.join(self.documents_dir, filename)\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    documents.append(file.read())\n",
    "            elif filename.endswith('.pdf'):\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    pdf_reader = PyPDF2.PdfReader(file)\n",
    "                    for page in pdf_reader.pages:\n",
    "                        documents.append(page.extract_text())\n",
    "            elif filename.endswith('.docx'):\n",
    "                doc = docx.Document(file_path)\n",
    "                documents.append('\\n'.join([paragraph.text for paragraph in doc.paragraphs]))\n",
    "        return documents\n",
    "\n",
    "    def process_documents(self):\n",
    "        \"\"\"Process documents and create vector store.\"\"\"\n",
    "        # Load documents\n",
    "        documents = self.load_documents()\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vector_store = FAISS.from_documents(chunks, self.embeddings)\n",
    "        \n",
    "        # Create QA chain\n",
    "        self.qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "            llm=self.llm,\n",
    "            retriever=self.vector_store.as_retriever(),\n",
    "            memory=self.memory,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "    def query(self, question: str) -> Dict:\n",
    "        \"\"\"Query the RAG system with a question.\"\"\"\n",
    "        if not self.qa_chain:\n",
    "            raise ValueError(\"Please process documents first by calling process_documents()\")\n",
    "        \n",
    "        result = self.qa_chain({\"question\": question})\n",
    "        return {\n",
    "            \"answer\": result[\"answer\"],\n",
    "            \"source_documents\": result[\"source_documents\"]\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Initialize RAG system\n",
    "    rag = FoodReviewRAG(\"foodreview\")\n",
    "    \n",
    "    # Process documents\n",
    "    print(\"Processing documents...\")\n",
    "    rag.process_documents()\n",
    "    print(\"Documents processed successfully!\")\n",
    "    \n",
    "    # Interactive query loop\n",
    "    print(\"\\nAsk questions about food reviews (type 'quit' to exit):\")\n",
    "    while True:\n",
    "        question = input(\"\\nYour question: \")\n",
    "        if question.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            result = rag.query(question)\n",
    "            print(\"\\nAnswer:\", result[\"answer\"])\n",
    "            print(\"\\nSources:\")\n",
    "            for doc in result[\"source_documents\"]:\n",
    "                print(\"-\", doc.page_content[:200], \"...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genai)",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
